import os
import streamlit as st
from langchain.chains import RetrievalQA, LLMChain
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from notion_client import Client as NotionClient
from datetime import datetime
from langchain.prompts import PromptTemplate
import json

# ========================
# ç’°å¢ƒå¤‰æ•°ã¨è¨­å®š
# ========================
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
notion_token = os.getenv("NOTION_API_KEY")
notion_db_id = os.getenv("NOTION_DATABASE_ID")

# Notionã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
notion = NotionClient(auth=notion_token)

# ========================
# ãƒ™ã‚¯ãƒˆãƒ«DBã¨LLMã®æº–å‚™
# ========================
embedding = OpenAIEmbeddings(api_key=openai_api_key, model="text-embedding-3-small")

try:
    print("ãƒ™ã‚¯ãƒˆãƒ«DBã‚’èª­ã¿è¾¼ã¿ä¸­...")
    vectorstore = Chroma(
        persist_directory="chroma_db",
        embedding_function=embedding,
        collection_metadata={"hnsw:space": "cosine"}
    )
    print("ãƒ™ã‚¯ãƒˆãƒ«DBã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
except Exception as e:
    st.error(f"ãƒ™ã‚¯ãƒˆãƒ«DBã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    st.error("ã‚·ã‚¹ãƒ†ãƒ ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„")
    st.stop()

# LLMã®åˆæœŸåŒ–
try:
    llm = ChatOpenAI(
        api_key=openai_api_key,
        temperature=0.3,
        model="gpt-3.5-turbo"
    )
except Exception as e:
    st.error(f"LLMã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    st.error("APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    st.stop()

# å›ç­”ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆcreate_retrieval_chainç”¨ã«ä¿®æ­£ï¼‰
answer_template = """
ã‚ãªãŸã¯æ­£ç¢ºã§è©³ç´°ãªå›ç­”ã‚’æä¾›ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±æºã®ã¿ã«åŸºã¥ã„ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
æƒ…å ±æºã«ãªã„å†…å®¹ã«ã¤ã„ã¦ã¯ã€Œè©²å½“ã™ã‚‹æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨æ˜ç¢ºã«ä¼ãˆã¦ãã ã•ã„ã€‚

å‚è€ƒæƒ…å ±:
{context}

è³ªå•: {input}

å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ï¼š
1. ç›´æ¥çš„ãªå›ç­”ï¼ˆç°¡æ½”ã‹ã¤å…·ä½“çš„ã«ï¼‰
2. å‚è€ƒæƒ…å ±ã‹ã‚‰ã®å…·ä½“çš„ãªå¼•ç”¨ï¼ˆè©²å½“ç®‡æ‰€ã‚’ã€Œã€ã§å›²ã‚€ï¼‰
3. è£œè¶³èª¬æ˜ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
4. æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¤º

å›ç­”:"""

# RetrievalQAãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
def create_qa_chain(k_docs=12):
    """QAãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã™ã‚‹é–¢æ•°"""
    try:
        from langchain.chains import create_retrieval_chain
        from langchain.chains.combine_documents import create_stuff_documents_chain
        from langchain.prompts import PromptTemplate

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ
        PROMPT = PromptTemplate(
            template=answer_template,
            input_variables=["context", "input"]
        )

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçµåˆãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        document_chain = create_stuff_documents_chain(llm, PROMPT)
        
        # æ¤œç´¢ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
        retriever = vectorstore.as_retriever(search_kwargs={"k": k_docs})
        qa_chain = create_retrieval_chain(retriever, document_chain)
        
        return qa_chain
    except Exception as e:
        st.error(f"QAãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        st.error("å¾“æ¥ã®æ–¹æ³•ã§å†è©¦è¡Œã—ã¾ã™...")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®RetrievalQAã‚’ä½¿ç”¨
        try:
            PROMPT = PromptTemplate(
                template="""å‚è€ƒæƒ…å ±:
{context}

è³ªå•: {question}

å›ç­”:""",
                input_variables=["context", "question"]
            )
            
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=vectorstore.as_retriever(search_kwargs={"k": k_docs}),
                return_source_documents=True,
                chain_type_kwargs={"prompt": PROMPT}
            )
            return qa_chain, "legacy"
        except Exception as e2:
            st.error(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—ã—ã¾ã—ãŸ: {str(e2)}")
            st.stop()

# è³ªå•åˆ†é¡ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
classification_template = """
ã‚ãªãŸã¯è³ªå•ã‚’åˆ†æã—ã€é©åˆ‡ãªæ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ææ¡ˆã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

1. è³ªå•ã®ç¨®é¡ï¼ˆæŠ€è¡“çš„è³ªå•ã€æ“ä½œæ–¹æ³•ã€ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ãªã©ï¼‰
2. ä¸»è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ3-5å€‹ï¼‰
3. æ¤œç´¢ã«ä½¿ç”¨ã™ã¹ãå…·ä½“çš„ãªãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆ2-3å€‹ï¼‰
4. è¿½åŠ ã§ç¢ºèªã™ã¹ãé–¢é€£ãƒˆãƒ”ãƒƒã‚¯

è³ªå•: {input_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚ã‚«ãƒ³ãƒã®ä½ç½®ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
{{
    "question_type": "è³ªå•ã®ç¨®é¡",
    "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"],
    "search_phrases": ["ãƒ•ãƒ¬ãƒ¼ã‚º1", "ãƒ•ãƒ¬ãƒ¼ã‚º2"],
    "related_topics": ["é–¢é€£ãƒˆãƒ”ãƒƒã‚¯1", "é–¢é€£ãƒˆãƒ”ãƒƒã‚¯2"]
}}
"""

def classify_question(question):
    """è³ªå•ã‚’åˆ†é¡ã—ã€æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹"""
    try:
        # ç›´æ¥LLMã‚’ä½¿ç”¨ã—ã¦JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—
        response = llm.invoke(
            classification_template.format(input_text=question)
        )
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡ºã—ã¦è§£æ
        try:
            # ä½™åˆ†ãªç©ºç™½ã‚„æ”¹è¡Œã‚’å‰Šé™¤ã—ã¦JSONã‚’æ•´å½¢
            json_str = response.content.strip()
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            st.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.error(f"å—ã‘å–ã£ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.content}")
            # JSONè§£æã«å¤±æ•—ã—ãŸå ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            return {
                "question_type": "ä¸€èˆ¬çš„ãªè³ªå•",
                "keywords": ["ä¸€èˆ¬"],
                "search_phrases": [question],
                "related_topics": []
            }
    except Exception as e:
        st.error(f"è³ªå•åˆ†é¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return {
            "question_type": "ä¸€èˆ¬çš„ãªè³ªå•",
            "keywords": ["ä¸€èˆ¬"],
            "search_phrases": [question],
            "related_topics": []
        }

# ========================
# Streamlit UI
# ========================
st.set_page_config(page_title="Chat with Vector DB", layout="wide")
st.title("ğŸ’¬ Chat with Knowledge Base")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¨­å®šã‚’è¿½åŠ 
with st.sidebar:
    st.header("è¨­å®š")
    temperature = st.slider(
        "å›ç­”ã®å‰µé€ æ€§",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.1,
        help="å€¤ã‚’å¤§ããã™ã‚‹ã¨ã‚ˆã‚Šå‰µé€ çš„ãªå›ç­”ã«ãªã‚Šã¾ã™ãŒã€ä¸€è²«æ€§ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    )
    
    # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã‚’è¿½åŠ 
    k_documents = st.slider(
        "å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°",
        min_value=1,
        max_value=20,
        value=12,
        step=1,
        help="æ¤œç´¢æ™‚ã«å‚ç…§ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ•°ã€‚å¤šã™ãã‚‹ã¨å‡¦ç†ãŒé…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    )
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«ãƒã‚§ãƒ¼ãƒ³ã‚’å†ä½œæˆ
    if 'last_k_documents' not in st.session_state:
        st.session_state.last_k_documents = k_documents
    
    if st.session_state.last_k_documents != k_documents:
        st.session_state.last_k_documents = k_documents
        st.session_state.qa_chain = None  # ãƒã‚§ãƒ¼ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ

# QAãƒã‚§ãƒ¼ãƒ³ã®åˆæœŸåŒ–ï¼ˆå¿…è¦æ™‚ã®ã¿ï¼‰
if 'qa_chain' not in st.session_state or st.session_state.qa_chain is None:
    with st.spinner("ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­..."):
        result = create_qa_chain(k_documents)
        if isinstance(result, tuple):
            st.session_state.qa_chain, chain_type = result
            st.session_state.chain_type = chain_type
        else:
            st.session_state.qa_chain = result
            st.session_state.chain_type = "modern"

# LLMã®æ¸©åº¦ã‚’å‹•çš„ã«æ›´æ–°
llm.temperature = temperature

# è³ªå•å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if query:
    try:
        # @queryã§å§‹ã¾ã‚‹å ´åˆã¯JSONã¨ã—ã¦è§£æ
        if query.startswith("@query"):
            try:
                # @queryã‚’é™¤å»ã—ã¦JSONã‚’è§£æ
                json_str = query[6:].strip()
                query_data = json.loads(json_str)
                # search_phrasesã‹ã‚‰æœ€åˆã®æ¤œç´¢ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ä½¿ç”¨
                if "search_phrases" in query_data and query_data["search_phrases"]:
                    query = query_data["search_phrases"][0]
                else:
                    st.warning("æ¤œç´¢ãƒ•ãƒ¬ãƒ¼ã‚ºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è³ªå•ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¾ã™ã€‚")
            except json.JSONDecodeError as e:
                st.error(f"JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                st.error("é€šå¸¸ã®è³ªå•ã¨ã—ã¦å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")

        with st.spinner("è³ªå•ã‚’åˆ†æä¸­..."):
            # Step 1: è³ªå•ã®åˆ†é¡
            classification = classify_question(query)
            
            st.markdown("### ğŸ“‹ è³ªå•ã®åˆ†æ:")
            st.json(classification)
            
            # Step 2: é–¢é€£æ–‡æ›¸ã®æ¤œç´¢ã¨å›ç­”ç”Ÿæˆ
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                try:
                    # ãƒã‚§ãƒ¼ãƒ³ã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‘¼ã³å‡ºã—æ–¹æ³•ã‚’å¤‰æ›´
                    if st.session_state.chain_type == "legacy":
                        result = st.session_state.qa_chain.invoke({"query": query})
                        answer = result["result"]
                        retrieved_documents = result.get("source_documents", [])
                    else:
                        result = st.session_state.qa_chain.invoke({"input": query})
                        answer = result["answer"]
                        retrieved_documents = result.get("context", [])
                    
                    # å›ç­”ã®è¡¨ç¤º
                    st.markdown("### ğŸ“˜ å›ç­”:")
                    st.write(answer)

                    # å‚ç…§å…ƒã®è©³ç´°è¡¨ç¤º
                    if retrieved_documents:
                        st.markdown("### ğŸ” å‚ç…§å…ƒè©³ç´°:")
                        for i, doc in enumerate(retrieved_documents, 1):
                            source = doc.metadata.get('source', 'ä¸æ˜')
                            title = doc.metadata.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
                            page = doc.metadata.get('page', 'ä¸æ˜')
                            
                            score = doc.metadata.get('score', 0.5)
                            
                            with st.expander(f"å‚ç…§å…ƒ {i}: {title} (ãƒšãƒ¼ã‚¸: {page}, ãƒ•ã‚¡ã‚¤ãƒ«: {source})"):
                                st.markdown(doc.page_content)
                                st.caption(f"é–¢é€£åº¦ã‚¹ã‚³ã‚¢: {score:.2f}")
                                if 'page' in doc.metadata:
                                    st.caption(f"ãƒšãƒ¼ã‚¸ç•ªå·: {doc.metadata['page']}")
                                if 'title' in doc.metadata:
                                    st.caption(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {doc.metadata['title']}")
                    else:
                        st.warning("é–¢é€£ã™ã‚‹å‚ç…§å…ƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                        
                except Exception as e:
                    st.error(f"å›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±:")
                    st.exception(e)
                    answer = "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

                # Notionã«ä¿å­˜
                def save_to_notion(feedback="pending"):
                    try:
                        notion.pages.create(
                            parent={"database_id": notion_db_id},
                            properties={
                                "è³ªå•": {
                                    "title": [
                                        {
                                            "text": {
                                                "content": query
                                            }
                                        }
                                    ]
                                },
                                "å›ç­”": {
                                    "rich_text": [
                                        {
                                            "text": {
                                                "content": answer
                                            }
                                        }
                                    ]
                                },
                                "è©•ä¾¡": {
                                    "multi_select": [
                                        {
                                            "name": feedback
                                        }
                                    ]
                                },
                                "æ—¥æ™‚": {
                                    "date": {
                                        "start": datetime.now().isoformat()
                                    }
                                },
                                "è³ªå•åˆ†é¡": {
                                    "rich_text": [
                                        {
                                            "text": {
                                                "content": classification["question_type"]
                                            }
                                        }
                                    ]
                                }
                            }
                        )
                        return True
                    except Exception as e:
                        st.error(f"Notionã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        return False

                col1, col2, col3 = st.columns(3)
                if col1.button("ğŸ‘ Good"):
                    if save_to_notion("good"):
                        st.success("Notionã« Good è©•ä¾¡ã§ä¿å­˜ã—ã¾ã—ãŸ")

                if col2.button("ğŸ‘ Bad"):
                    if save_to_notion("bad"):
                        st.warning("Notionã« Bad è©•ä¾¡ã§ä¿å­˜ã—ã¾ã—ãŸ")

                if col3.button("â³ Pending"):
                    if save_to_notion("pending"):
                        st.info("Notionã« Pending è©•ä¾¡ã§ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.error("ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±:")
        st.exception(e)